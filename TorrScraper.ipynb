{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraper using Tor\n",
    "This web scraper can be re-appropriated to scrape any website. It uses both selenium and Tor to scrape the most protected websites. Selenium mimics human behaviors when scraping and won't trip the website into thinking a bot is scraping it-- so it'll prevent a CAPTCHA from appearing. The Tor network allows you to tunnel your IP through the Tor network which prevents your IP from being banned. This is extremely useful if you need to scrape a large amount of data in a short time period. However, when scraping, always keep in mind that you can unncessarily load the site you're scraping from, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from time import time\n",
    "from random import randint\n",
    "from IPython.core.display import clear_output\n",
    "from warnings import warn\n",
    "import matplotlib.pyplot\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import socks\n",
    "import socket\n",
    "import stem.process\n",
    "\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = webdriver.ChromeOptions()\n",
    "browser = webdriver.Chrome(executable_path=\"../chromedriver\", \n",
    "                           chrome_options=option)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"www.yoururl.com\")\n",
    "browser.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requests: 22723; Frequency: 0.9398818826723617 requests/s\n"
     ]
    }
   ],
   "source": [
    "SOCKS_PORT=7000# You can change the port number\n",
    "\n",
    "tor_process = stem.process.launch_tor_with_config(\n",
    "    config = {\n",
    "        'SocksPort': str(SOCKS_PORT),\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "socks.setdefaultproxy(proxy_type=socks.PROXY_TYPE_SOCKS5,\n",
    "                      addr=\"127.0.0.1\", \n",
    "                      port=SOCKS_PORT)\n",
    "socket.socket = socks.socksocket\n",
    "\n",
    "#Creating names for variables\n",
    "user_name = []\n",
    "strain_name = []\n",
    "date_times = []\n",
    "reviews = []\n",
    "\n",
    "#Preparing the scraper monitoring system\n",
    "start_time = time()\n",
    "requests = 0\n",
    "\n",
    "#Loop over these profile names\n",
    "profiles = third\n",
    "\n",
    "\n",
    "for page in profiles:\n",
    "    \n",
    "    #Make request\n",
    "    url = (\"www.yoururl.com\" + page)\n",
    "    browser.get(url)\n",
    "    \n",
    "    #Pause the loop\n",
    "    #sleep(randint(1,3))\n",
    "    \n",
    "    #Monitor the requests\n",
    "    requests += 1\n",
    "    elapsed_time = time() - start_time\n",
    "    print('Requests: {}; Frequency: {} requests/s'.format (requests, requests/elapsed_time))\n",
    "    clear_output(wait=True)\n",
    "            \n",
    "    #Break the loop if requests greater than expected\n",
    "        #if requests > 1200:\n",
    "            #warn('Number of requests was greater than expected')\n",
    "            #break\n",
    "\n",
    "    #This code will be dependent on the HTML on the page you're trying to scrape\n",
    "    sn = browser.find_elements_by_xpath(\"//a[@class='jsx-3280173133']\")\n",
    "    strain_name.append([x.text for x in sn])\n",
    "    \n",
    "    un = browser.find_elements_by_xpath(\"//div[@class='jsx-2350928015 user-name']\")\n",
    "    user_name.append([x.text for x in un])\n",
    "\n",
    "    cd = browser.find_elements_by_xpath(\"//span[@class='jsx-3280173133 date']\")\n",
    "    date_times.append([x.text for x in cd])\n",
    "\n",
    "    rt = browser.find_elements_by_xpath(\"//div[@class='jsx-3280173133 review-text']\")\n",
    "    reviews.append([x.text for x in rt])\n",
    "\n",
    "    \n",
    "tor_process.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
